import os
import torch
import numpy as np
from torch.utils.data import DataLoader, random_split
from torch.optim.lr_scheduler import CosineAnnealingLR
from torchvision import transforms

from dataset import ROI12ImageDataset
from model import YOLO11ROIClassifier, calculate_3c_metrics, evaluate
from loss import YOLO11ROIFocalLoss3C

# ===================== æ ¸å¿ƒé…ç½®ï¼ˆæ”¯æŒn/s/låˆ‡æ¢ï¼‰ =====================
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
ROI_IMG_SIZE = 64
NUM_ROI = 12
NUM_CLASSES = 3
MODEL_SIZE = "s"  # å¯é€‰ï¼š"n"ï¼ˆæœ€å¿«ï¼‰ã€"s"ï¼ˆå¹³è¡¡ï¼‰ã€"l"ï¼ˆæœ€å‡†ï¼‰
# æ ¹æ®æ¨¡å‹å°ºå¯¸è‡ªé€‚åº”è¶…å‚æ•°
BATCH_SIZE = 16
EPOCHS = 100
LEARNING_RATE = 5e-5 if MODEL_SIZE == "l" else 1e-4 if MODEL_SIZE == "s" else 1e-3
WEIGHT_DECAY = 5e-4
DATASET_ROOT = r"H:\pycharm\yolov11\yolov11_proj1\datasets_16334"
SAVE_DIR = "./checkpoints"
VAL_RATIO = 0.2

# ===================== æ•°æ®é¢„å¤„ç† =====================
yolo11_mean = [0.485, 0.456, 0.406]
yolo11_std = [0.229, 0.224, 0.225]

train_transform = transforms.Compose([
    transforms.ToPILImage(),
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomRotation(5),
    transforms.ToTensor(),
    transforms.Normalize(mean=yolo11_mean, std=yolo11_std)
])

val_test_transform = transforms.Compose([
    transforms.ToPILImage(),
    transforms.ToTensor(),
    transforms.Normalize(mean=yolo11_mean, std=yolo11_std)
])

# ===================== åŠ è½½æ•°æ®é›† =====================
full_dataset = ROI12ImageDataset(
    dataset_root=DATASET_ROOT,
    roi_img_size=ROI_IMG_SIZE,
    transform=None
)
val_size = int(VAL_RATIO * len(full_dataset))
train_size = len(full_dataset) - val_size
train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])

train_dataset.dataset.transform = train_transform
val_dataset.dataset.transform = val_test_transform

train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8, pin_memory=False)
val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8, pin_memory=False)

print(f"=== æ•°æ®é›†åˆ’åˆ†å®Œæˆ ===")
print(f"è®­ç»ƒé›†ï¼š{train_size}æ ·æœ¬ | {len(train_loader)}æ‰¹æ¬¡")
print(f"éªŒè¯é›†ï¼š{val_size}æ ·æœ¬ | {len(val_loader)}æ‰¹æ¬¡")
print(f"è®­ç»ƒè®¾å¤‡ï¼š{DEVICE} | æ¨¡å‹å°ºå¯¸ï¼šYOLO11-{MODEL_SIZE.upper()}")
print("=" * 80)

# ===================== åˆå§‹åŒ–æ¨¡å‹/æŸå¤±/ä¼˜åŒ–å™¨ =====================
model = YOLO11ROIClassifier(
    model_size=MODEL_SIZE,  # ä¼ å…¥æ¨¡å‹å°ºå¯¸
    num_roi=NUM_ROI,
    num_classes=NUM_CLASSES,
    roi_size=ROI_IMG_SIZE
).to(DEVICE)

loss_fn = YOLO11ROIFocalLoss3C(
    num_roi=NUM_ROI,
    num_classes=NUM_CLASSES,
    alpha=[1.0, 3.0, 2.0],
    gamma=1.5,
    max_positive=8,
    max_negative=4
).to(DEVICE)

# åˆ†å±‚å­¦ä¹ ç‡ï¼ˆå¤§æ¨¡å‹Backboneå­¦ä¹ ç‡æ›´ä½ï¼‰
lr_scale = 0.005 if MODEL_SIZE == "l" else 0.01 if MODEL_SIZE == "s" else 0.03
param_groups = [
    {"params": model.backbone.parameters(), "lr": LEARNING_RATE * lr_scale},
    {"params": model.neck.parameters(), "lr": LEARNING_RATE},
    {"params": model.head.parameters(), "lr": LEARNING_RATE},
]
optimizer = torch.optim.AdamW(param_groups, weight_decay=WEIGHT_DECAY)
scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-6)

# ===================== è®­ç»ƒé›†æµ‹è¯•å‡½æ•° =====================
def test_train_set(model, train_loader, device):
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for batch_idx, (roi_imgs, cls_target, roi_valid_mask) in enumerate(train_loader):
            roi_imgs = roi_imgs.to(device)
            cls_target = cls_target.to(device)
            roi_valid_mask = roi_valid_mask.to(device)

            pred_logits = model(roi_imgs)
            pred_cls = torch.argmax(pred_logits, dim=-1)
            pred_cls[~roi_valid_mask] = 0

            correct += (pred_cls == cls_target).sum().item()
            total += cls_target.numel()

            if batch_idx < 3:
                print(f"ã€è®­ç»ƒé›†æµ‹è¯•ã€‘Batch {batch_idx}")
                print(f"çœŸå®æ ‡ç­¾ï¼š{cls_target[0].cpu().numpy()}")
                print(f"é¢„æµ‹æ ‡ç­¾ï¼š{pred_cls[0].cpu().numpy()}")
                print("-" * 50)

    acc = correct / total
    print(f"\nè®­ç»ƒé›†æ•´ä½“å‡†ç¡®ç‡ï¼š{acc:.4f}")
    model.train()
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
    return acc

# ===================== è®­ç»ƒå¾ªç¯ =====================
os.makedirs(SAVE_DIR, exist_ok=True)
best_pos_f1 = 0.0
patience = 8
no_improve = 0

print(f"=== å¼€å§‹è®­ç»ƒï¼ˆYOLO11-{MODEL_SIZE.upper()}åŸç”Ÿè®­ç»ƒç­–ç•¥ï¼‰ ===")
print("\n=== è®­ç»ƒå‰æµ‹è¯•è®­ç»ƒé›† ===")
test_train_set(model, train_loader, DEVICE)

for epoch in range(EPOCHS):
    model.train()
    epoch_loss = 0.0
    batch_count = 0

    train_total_acc = 0.0
    train_valid_acc = 0.0
    train_pos_acc, train_pos_precision, train_pos_recall, train_pos_f1 = 0.0,0.0,0.0,0.0
    train_neg_acc, train_neg_precision, train_neg_recall, train_neg_f1 = 0.0,0.0,0.0,0.0

    for batch_idx, (roi_imgs, cls_target, roi_valid_mask) in enumerate(train_loader):
        roi_imgs = roi_imgs.to(DEVICE)
        cls_target = cls_target.to(DEVICE)

        pred_logits = model(roi_imgs)
        loss = loss_fn(pred_logits, cls_target)

        optimizer.zero_grad()
        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
        optimizer.step()

        epoch_loss += loss.item()
        batch_count += 1

        metrics = calculate_3c_metrics(pred_logits, cls_target)
        train_total_acc += metrics["total_acc"]
        train_valid_acc += metrics["valid_acc"]
        train_pos_acc += metrics["pos_metrics"]["acc"]
        train_pos_precision += metrics["pos_metrics"]["precision"]
        train_pos_recall += metrics["pos_metrics"]["recall"]
        train_pos_f1 += metrics["pos_metrics"]["f1"]
        train_neg_acc += metrics["neg_metrics"]["acc"]
        train_neg_precision += metrics["neg_metrics"]["precision"]
        train_neg_recall += metrics["neg_metrics"]["recall"]
        train_neg_f1 += metrics["neg_metrics"]["f1"]

        if (batch_idx + 1) % 10 == 0:
            print(f"Epoch [{epoch + 1}/{EPOCHS}] | Batch [{batch_idx + 1}/{len(train_loader)}] | Loss: {loss.item():.4f} | LR: {optimizer.param_groups[0]['lr']:.6f}")

    scheduler.step()

    # è®¡ç®—è®­ç»ƒé›†å¹³å‡æŒ‡æ ‡
    avg_epoch_loss = epoch_loss / batch_count if batch_count>0 else 0.0
    avg_train_total_acc = train_total_acc / batch_count if batch_count>0 else 0.0
    avg_train_valid_acc = train_valid_acc / batch_count if batch_count>0 else 0.0
    avg_train_pos_acc = train_pos_acc / batch_count if batch_count>0 else 0.0
    avg_train_pos_precision = train_pos_precision / batch_count if batch_count>0 else 0.0
    avg_train_pos_recall = train_pos_recall / batch_count if batch_count>0 else 0.0
    avg_train_pos_f1 = train_pos_f1 / batch_count if batch_count>0 else 0.0
    avg_train_neg_acc = train_neg_acc / batch_count if batch_count>0 else 0.0
    avg_train_neg_precision = train_neg_precision / batch_count if batch_count>0 else 0.0
    avg_train_neg_recall = train_neg_recall / batch_count if batch_count>0 else 0.0
    avg_train_neg_f1 = train_neg_f1 / batch_count if batch_count>0 else 0.0

    # éªŒè¯é›†è¯„ä¼°
    val_metrics = evaluate(model, val_loader, loss_fn, DEVICE)
    (avg_val_loss, val_roi_avg_loss, avg_val_total_acc, avg_val_valid_acc,
     avg_val_pos_acc, avg_val_pos_precision, avg_val_pos_recall, avg_val_pos_f1,
     avg_val_neg_acc, avg_val_neg_precision, avg_val_neg_recall, avg_val_neg_f1) = val_metrics

    # æ‰“å°æ—¥å¿—
    print("=" * 120)
    print(f"ã€Epoch {epoch + 1}/{EPOCHS} è®­ç»ƒé›†ï¼ˆYOLO11-{MODEL_SIZE.upper()}ï¼‰ã€‘")
    print(f"æ€»æŸå¤±ï¼š{avg_epoch_loss:.4f} | æ•´ä½“å‡†ç¡®ç‡ï¼š{avg_train_total_acc:.4f} | æœ‰æ•ˆROIå‡†ç¡®ç‡ï¼š{avg_train_valid_acc:.4f}")
    print(f"â”œâ”€ æœ‰æ•ˆæœ‰æ–¹å—ï¼ˆ2ç±»ï¼‰ï¼šå‡†ç¡®ç‡={avg_train_pos_acc:.4f} | ç²¾ç¡®ç‡={avg_train_pos_precision:.4f} | å¬å›ç‡={avg_train_pos_recall:.4f} | F1={avg_train_pos_f1:.4f}")
    print(f"â””â”€ æœ‰æ•ˆæ— æ–¹å—ï¼ˆ1ç±»ï¼‰ï¼šå‡†ç¡®ç‡={avg_train_neg_acc:.4f} | ç²¾ç¡®ç‡={avg_train_neg_precision:.4f} | å¬å›ç‡={avg_train_neg_recall:.4f} | F1={avg_train_neg_f1:.4f}")

    print(f"ã€Epoch {epoch + 1}/{EPOCHS} éªŒè¯é›†ï¼ˆYOLO11-{MODEL_SIZE.upper()}ï¼‰ã€‘")
    print(f"æ€»æŸå¤±ï¼š{avg_val_loss:.4f} | æ•´ä½“å‡†ç¡®ç‡ï¼š{avg_val_total_acc:.4f} | æœ‰æ•ˆROIå‡†ç¡®ç‡ï¼š{avg_val_valid_acc:.4f}")
    print(f"â”œâ”€ æœ‰æ•ˆæœ‰æ–¹å—ï¼ˆ2ç±»ï¼‰ï¼šå‡†ç¡®ç‡={avg_val_pos_acc:.4f} | ç²¾ç¡®ç‡={avg_val_pos_precision:.4f} | å¬å›ç‡={avg_val_pos_recall:.4f} | F1={avg_val_pos_f1:.4f}")
    print(f"â””â”€ æœ‰æ•ˆæ— æ–¹å—ï¼ˆ1ç±»ï¼‰ï¼šå‡†ç¡®ç‡={avg_val_neg_acc:.4f} | ç²¾ç¡®ç‡={avg_val_neg_precision:.4f} | å¬å›ç‡={avg_val_neg_recall:.4f} | F1={avg_val_neg_f1:.4f}")
    print("=" * 120)

    # æ—©åœ+ä¿å­˜æ¨¡å‹
    if avg_val_pos_f1 > best_pos_f1:
        best_pos_f1 = avg_val_pos_f1
        no_improve = 0
        save_path = os.path.join(SAVE_DIR, f"yolo11_{MODEL_SIZE}_roi_best_3c.pt")
        torch.save({
            'epoch': epoch + 1,
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'best_pos_f1': best_pos_f1,
            'loss': avg_val_loss,
        }, save_path)
        print(f"âœ… ä¿å­˜YOLO11-{MODEL_SIZE.upper()}æœ€ä¼˜æ¨¡å‹ | æœ‰æ•ˆæœ‰æ–¹å—F1ï¼š{avg_val_pos_f1:.4f} | è·¯å¾„ï¼š{save_path}")
    else:
        no_improve += 1
        print(f"âš ï¸ æ­£æ ·æœ¬F1æœªæå‡ | å½“å‰æœ€ä¼˜ï¼š{best_pos_f1:.4f} | æ— æå‡è½®æ•°ï¼š{no_improve}/{patience}")
        if no_improve >= patience:
            print("ğŸš¨ æ—©åœè§¦å‘ï¼šéªŒè¯é›†æ­£æ ·æœ¬F1ä¸å†æå‡")
            break

    # ä¿å­˜æœ¬è½®æ¨¡å‹
    epoch_save_path = os.path.join(SAVE_DIR, f"yolo11_{MODEL_SIZE}_roi_epoch_{epoch + 1}_3c.pt")
    torch.save(model.state_dict(), epoch_save_path)

    # æ¯10è½®æµ‹è¯•è®­ç»ƒé›†
    if (epoch + 1) % 10 == 0:
        print(f"\n=== Epoch {epoch + 1} è®­ç»ƒé›†æµ‹è¯•ï¼ˆYOLO11-{MODEL_SIZE.upper()}ï¼‰ ===")
        test_train_set(model, train_loader, DEVICE)

print("=== YOLO11è®­ç»ƒå®Œæˆ ===")
print(f"æœ€ä¼˜æ¨¡å‹è·¯å¾„ï¼š{os.path.join(SAVE_DIR, f'yolo11_{MODEL_SIZE}_roi_best_3c.pt')}")
print(f"æœ€ä¼˜æ­£æ ·æœ¬F1ï¼š{best_pos_f1:.4f}")
